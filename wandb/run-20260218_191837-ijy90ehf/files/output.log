Epoch 1/3:   0%|          | 0/14 [00:00<?, ?it/s]/u/fvc9ch/nlp_research/VLLM-math-generation/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/u/fvc9ch/nlp_research/VLLM-math-generation/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:659: UserWarning: pin_memory_device is deprecated, the current accelerator will be used as the device,ignore pin_memory_device='cuda'.
  warnings.warn(
step:1 - train/loss:0.7198879718780518 - train/lr(1e-3):0.0025 - train/time(s):144.65575671195984
Epoch 1/3: 100%|██████████| 14/14 [32:03<00:00, 137.37s/it]
step:2 - train/loss:0.7045859098434448 - train/lr(1e-3):0.005 - train/time(s):136.0225749015808
step:3 - train/loss:0.7082213163375854 - train/lr(1e-3):0.0075000000000000015 - train/time(s):134.74046182632446
step:4 - train/loss:0.7018717527389526 - train/lr(1e-3):0.01 - train/time(s):135.33717226982117
step:5 - train/loss:0.6983081698417664 - train/lr(1e-3):0.00998292246503335 - train/time(s):135.87508821487427
step:6 - train/loss:0.7037407755851746 - train/lr(1e-3):0.009931806517013612 - train/time(s):135.3831627368927
step:7 - train/loss:0.6782772541046143 - train/lr(1e-3):0.009847001329696653 - train/time(s):135.73297333717346
step:8 - train/loss:0.6816440224647522 - train/lr(1e-3):0.009729086208503174 - train/time(s):135.72747993469238
step:9 - train/loss:0.6625444889068604 - train/lr(1e-3):0.009578866633275288 - train/time(s):136.10663652420044
step:10 - train/loss:0.6571380496025085 - train/lr(1e-3):0.009397368756032445 - train/time(s):135.22993445396423
step:11 - train/loss:0.661663830280304 - train/lr(1e-3):0.009185832391312643 - train/time(s):134.97639203071594
step:12 - train/loss:0.6464588642120361 - train/lr(1e-3):0.00894570254698197 - train/time(s):135.4219536781311
step:13 - train/loss:0.6401014924049377 - train/lr(1e-3):0.008678619553365659 - train/time(s):135.3043327331543
step:14 - train/loss:0.6520530581474304 - train/lr(1e-3):0.008386407858128707 - train/time(s):135.49424767494202
Epoch 2/3:   0%|          | 0/14 [00:00<?, ?it/s]/u/fvc9ch/nlp_research/VLLM-math-generation/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/u/fvc9ch/nlp_research/VLLM-math-generation/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:659: UserWarning: pin_memory_device is deprecated, the current accelerator will be used as the device,ignore pin_memory_device='cuda'.
  warnings.warn(
step:15 - train/loss:0.642948567867279 - train/lr(1e-3):0.008071063563448342 - train/time(s):142.0695629119873
Epoch 2/3: 100%|██████████| 14/14 [31:57<00:00, 136.98s/it]
step:16 - train/loss:0.6220980882644653 - train/lr(1e-3):0.007734740790612137 - train/time(s):135.9927637577057
step:17 - train/loss:0.6389281153678894 - train/lr(1e-3):0.007379736965185369 - train/time(s):135.50716018676758
step:18 - train/loss:0.6406980156898499 - train/lr(1e-3):0.007008477123264849 - train/time(s):134.87748622894287
step:19 - train/loss:0.6222758293151855 - train/lr(1e-3):0.006623497346023418 - train/time(s):135.30780363082886
step:20 - train/loss:0.6409142017364502 - train/lr(1e-3):0.006227427435703997 - train/time(s):136.0749111175537
step:21 - train/loss:0.6153159141540527 - train/lr(1e-3):0.00582297295140367 - train/time(s):135.4915807247162
step:22 - train/loss:0.6221678256988525 - train/lr(1e-3):0.005412896727361663 - train/time(s):135.4289321899414
step:23 - train/loss:0.6185268759727478 - train/lr(1e-3):0.005 - train/time(s):136.34665608406067
step:24 - train/loss:0.629180371761322 - train/lr(1e-3):0.004587103272638339 - train/time(s):135.44538569450378
step:25 - train/loss:0.6125607490539551 - train/lr(1e-3):0.00417702704859633 - train/time(s):135.4133858680725
step:26 - train/loss:0.6189085841178894 - train/lr(1e-3):0.0037725725642960045 - train/time(s):135.53644037246704
step:27 - train/loss:0.6267717480659485 - train/lr(1e-3):0.0033765026539765834 - train/time(s):135.1437427997589
step:28 - train/loss:0.6034819483757019 - train/lr(1e-3):0.002991522876735154 - train/time(s):134.82338428497314
Epoch 3/3:  93%|█████████▎| 13/14 [29:43<02:15, 135.64s/it]/u/fvc9ch/nlp_research/VLLM-math-generation/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
step:29 - train/loss:0.6296445727348328 - train/lr(1e-3):0.0026202630348146324 - train/time(s):141.3714096546173
step:30 - train/loss:0.6140226125717163 - train/lr(1e-3):0.002265259209387867 - train/time(s):136.06658816337585
step:31 - train/loss:0.6178836822509766 - train/lr(1e-3):0.001928936436551661 - train/time(s):135.3296458721161
step:32 - train/loss:0.6067485809326172 - train/lr(1e-3):0.0016135921418712958 - train/time(s):136.16918206214905
step:33 - train/loss:0.6070869565010071 - train/lr(1e-3):0.0013213804466343422 - train/time(s):136.9793074131012
step:34 - train/loss:0.6187906265258789 - train/lr(1e-3):0.0010542974530180326 - train/time(s):135.0878927707672
step:35 - train/loss:0.6196527481079102 - train/lr(1e-3):0.0008141676086873574 - train/time(s):135.4798777103424
step:36 - train/loss:0.6092079281806946 - train/lr(1e-3):0.0006026312439675552 - train/time(s):135.2931044101715
step:37 - train/loss:0.6142517328262329 - train/lr(1e-3):0.00042113336672471247 - train/time(s):135.33821558952332
step:38 - train/loss:0.611728310585022 - train/lr(1e-3):0.0002709137914968268 - train/time(s):136.015695810318
step:39 - train/loss:0.6258296370506287 - train/lr(1e-3):0.00015299867030334815 - train/time(s):135.53998184204102
step:40 - train/loss:0.6116524934768677 - train/lr(1e-3):6.81934829863884e-05 - train/time(s):135.07583045959473
step:41 - train/loss:0.6281235218048096 - train/lr(1e-3):1.7077534966650767e-05 - train/time(s):135.77119636535645
step:42 - train/loss:0.6076881885528564 - train/lr(1e-3):0.0 - train/time(s):135.11587643623352
step:42 - val/loss:0.6147674322128296
  warnings.warn(  # warn only once
Saving checkpoint to: ./checkpoints/sft_qwen2.5_math_1.5b/global_step_42
[2026-02-18 20:56:11,389][/u/fvc9ch/nlp_research/verl/verl/utils/checkpoint/fsdp_checkpoint_manager.py][INFO] - [Rank 0] Saved model to /u/fvc9ch/nlp_research/VLLM-math-generation/checkpoints/sft_qwen2.5_math_1.5b/global_step_42/model_world_size_1_rank_0.pt
[2026-02-18 20:57:10,897][/u/fvc9ch/nlp_research/verl/verl/utils/checkpoint/fsdp_checkpoint_manager.py][INFO] - [Rank 0] Saved optim to /u/fvc9ch/nlp_research/VLLM-math-generation/checkpoints/sft_qwen2.5_math_1.5b/global_step_42/optim_world_size_1_rank_0.pt
[2026-02-18 20:57:10,903][/u/fvc9ch/nlp_research/verl/verl/utils/checkpoint/fsdp_checkpoint_manager.py][INFO] - [Rank 0] Saved extra_state to /u/fvc9ch/nlp_research/VLLM-math-generation/checkpoints/sft_qwen2.5_math_1.5b/global_step_42/extra_state_world_size_1_rank_0.pt
[2026-02-18 20:57:11,388][/u/fvc9ch/nlp_research/verl/verl/utils/checkpoint/fsdp_checkpoint_manager.py][INFO] - [Rank 0] Saved model config and tokenizer class to /u/fvc9ch/nlp_research/VLLM-math-generation/checkpoints/sft_qwen2.5_math_1.5b/global_step_42/huggingface
/u/fvc9ch/nlp_research/VLLM-math-generation/.venv/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
  warnings.warn(  # warn only once
Saved dataloader state to: ./checkpoints/sft_qwen2.5_math_1.5b/global_step_42/data.pt
Updated checkpoint tracker: ./checkpoints/sft_qwen2.5_math_1.5b/latest_checkpointed_iteration.txt
Total time for train steps: 5714.10s
Final validation metrics: {'val/loss': 0.6147674322128296}
Epoch 3/3:  93%|█████████▎| 13/14 [34:32<02:39, 159.40s/it]
